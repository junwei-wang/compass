---
title: Lattice
category: crypto-topics
layout: cayman
---

* TOC
{:toc}

Organized from the a talk entitled The Mathematics of Lattices ([1](https://youtu.be/LlPXfy6bKIY) &
[2](https://youtu.be/SZkTJMorxnM)) given by [Vinod Vaikuntanathan]({{ site.data.people["Vinod Vaikuntanathan"].url }}).

## Definition

> A $n$-dimensional lattice $L$ is all **integer** linear combinations of $n$ basis vectors $b_1,b_2,\cdots,b_n$.

In other words, $L$ is an additive group generated by $\\{b_1,b_2,\cdots,b_n\\}.$
The same lattice can be generated through several basis. A "good" basis means the vectors $(b_i)_i$ are short, while the
vectors are long for the "bad" basis.

## Basic Hard Problems

Here, "short" means a small [Euclidean norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm).

### Shortest Vector Problem (SVP)

> Given a basis (unbounded, i.e., could be good basis or bad basis), find the **shortest non-zero vector**.

Proven to be NP-hard!

#### $\alpha$-Approximate Shortest Vector Problem

> Given a basis, find $\alpha$-approximate shortest vector (a non-zero vector of length at most $\alpha \lambda_1$ where
> $\lambda_1$ is the length of the shortest vector).

- **LLL**: in polynomial time, we can find the at most length $2^{\frac{n}{2}}\lambda_1$ vector (i.e.,
  $2^\frac{n}{2}$-approximate SVP).
- Best known of $2^k$-approximation SVP is $2^{\widetilde{O}(n/k)}$. (even for quantum computers)

### Shortest Independent Vector Problem (SIVP)

> Let $\lambda_n = \min(r:$ there are $n$ linearly independent lattice vectors of length $\leq r.)$
> Given a basis, find $n$ vectors of length at most $\lambda_n$.

SVP and SIVP are two distinct interesting problems.


## Why Lattice in Crypto?

- Common-sense safety
- Quantum resistance (so far)
- Worst-case hardness (unique feature of lattice-based crypto)
- Simplicity and efficiency
- Tons of application (FHE, FE, Obfuscation, etc.)

For lattice problem, worst-case hardness = average-case hardness
**Worst-case hardness**: at least one instance hard (safest to assume)
**Average-case hardness**: average instance hard (preferred in crypto)

## From Hardness to Usefulness

- Short integer solutions (SIS)
  - One-way function [STOC96]
  - Collision-resistance hashing [STOC96,GGH96]
-  Learning with errors (LWE)
  - PRNG [STOC96,Regev05]
  - PKE [AD97,GGH97,HPS98,Regev05]
  - OT and secure MPC [PVW08]
- Lattice trapdoors
  - Trapdoor functions [Ajtai99,GPV08,MP12]
  - Digital signatures [GGH97,HPS98,GPV08,LyuMic08]
- Punctured trapdoors
  - IBE [GPV08,CHKP10,ABB10]
  - ABE [GVW13,BGGHNSVV14]
  - Predicate Encryption [GVW15]

### Other usage

- Cryptanalytic uses of lattice
- Ideal lattice, Ring-SIS and Ring-LWE

Primitives:
- PRF [BPR10,BLMR13]
- FHE [Gen09,BV11,GSW13]
- mmaps and Obfuscation (based on non-standard lattice problems) [GGH13,...]


## Short Integer Solutions ($\SIS_{q,n,m,\beta}$)

> Given a matrix $A \in \ZZ_{q}^{n\times m}$, find a vector $\vec{r} \in \ZZ^m$ s.t.
>  - $A\vec{r} = 0$ over $\ZZ_q^n$,
>  - $\norm{r} \leq \beta$.

$A$ is "short-and-fat" (underdetermined). For example, given equations systems over $\ZZ_q$,

$$
\left[
\begin{array}{ccc}
 5 & 2 & 3 \nonumber \\
 4 & 6 & 9 \nonumber
\end{array}
\right] \vec{r} = \left[
\begin{array}{c}
0 \\
0
\end{array}
\right].
$$

Without "short", we can easily give a solution by Gaussian elimination.


Generalization, $\SIS_{G,m,\beta}$
> Given a vector of group elements $(\mathbf{g}_1,\mathbf{g}_2,\cdots,\mathbf{g}_m) \in G^m$, find a vector $\vec{r} \in
> \ZZ^m$ s.t.
>  - $\sum r_i\mathbf{g}_i = \mathbf{0}$ over $G$,
>  - $\norm{r}_2 \leq \beta$.

That is,
$$
[\mathbf{g}_1,\mathbf{g}_2,\cdots,\mathbf{g}_m] \vec{r} = [\mathbf{0}].
$$

### Application: Collision-Resistant Hash Function

[STOC96,GGH96] gave the following a function $f_A:\\{0,1\\}^m \to \ZZ_q^n$, defined as $f_A(r)=Ar \mod q$ where $m >
\log{q}\cdot n$. It is a collision-resistant hash function (implying it is a one-way function as well).

Given a collision $(r, r')$, $A(r-r')=0 \mod q$ where $\norm{r-r'} \leq \sqrt{m}$

### Average Hardness of SIS

Proof sketch:

Given a hard (for SVP) lattice with base $B$ and a SIS oracle (e.g., every entry in solution is $\\{-1,0,1\\}$).,
computer a short vector in the lattice.

1. For $1\leq i \leq m$:
   - Pick a random lattice point $x_i$ (how to do this?)
   - Gaussian sample a point $y_i$ around the $x_i$ s.t. $y_i = x_i+e_i$ (where $e_i \leq $)
   - The coefficients of $y_i$ is written as $\mathbf{g}_i$ (i.e., $y_i=B\cdot \mathbf{g}_i)$ which is uniformly random
     if the Gaussian distribution is chosen nearly $\lambda_n$) and $y_i = $.
2. Make the SIS instance as $[\mathbf{g}_1,\mathbf{g}_2,\cdots,\mathbf{g}_m] \vec{r} = [\mathbf{0}].$, and sent it to
   the oracle.
3. The oracle send back the solution $\vec{r}$ s.t. $\sum_i r_i\mathbf{g}_i = 0 \mod q$.
4. Output $\sum r_i y_i$ as the short vector in the lattice. The norm is bounded to $\lambda_n\sqrt{m}$.

$$
\begin{array}{rcl}
\sum r_i y_i & = & \sum_i r_i (y_i + e_i) \\
             & = & \sum_i r_i y_i + \sum_i r_i e_i \\
			 & = & \sum_i r_i e_i
\end{array}
$$

## Learning with Errors (LWE)

> Given a matrix $\mathbf{A} \in \ZZ^{n\times m}_q$ and $s^T\mathbf{A}+e^T$ where $e$ is small "error" vector, find $s
> \in \ZZ^{n}_q$.

Without $e$, it is easily solved by Gaussian elimination. But with error, believed to be very hard!!!

Note $\mathbf{A}$ is overdetermined, which means the solution of $s$ is unique, making PKE possible. The core of LWE is
uniqueness.

**Hardness**: best algorithm is $q^{\O({n}/{\log n})}$ for $n$ variables, and even seems hard for quantum algorithms.

### Variant: decisional LWE

$$(\mathbf{A}, s^T\mathbf{A}+e) \overset{c}{\approx} (\mathbf{A},b)$$ for a uniformly random $b$.

d-LWE is as hard as LWE.

## References

- [STOC96] Ajtai. **Generating hard instances of lattice problems.**
  [ECCC](https://eccc.weizmann.ac.il/eccc-reports/1996/TR96-007/Paper.pdf)
  [ppt](/pdfs/slides/lattice-ajtai.ppt)
> We give a random class of $n$ dimensional lattices so that, if there is a probabilistic polynomial time algorithm which
> finds a short vector in a random lattice with a probability of at least 1/2 then there is also a probabilistic
> polynomial time algorithm which solves the following three lattice problems in every $n$ dimensional lattice with a
> probability exponentially close to one.
> 1. Find the length of a shortest nonzero vector in an $n$-dimensional lattice, approximately, up to a polynomial
> factor.
> 2. Find the shortest nonzero vector in an $n$-dimensional lattice $L$ where the shortest vector is unique in the
> sense that any other vector whose length is only a polynomial times longer, is parallel to it.
> 3. Find a basis in the lattice $L$ whose length is the smallest possible up to a polynomial factor, where the
>  length of a basis is the maximum of the lengths of its elements.

- [GGH96] Goldreich,Goldwasser,Halevi **Collision-Free Hashing from Lattice Problems.**
  [ia.cr/1996/009](http://ia.cr/1996/009) | [weizmann](http://www.wisdom.weizmann.ac.il/~oded/COL/cfh.pdf)
> Recently Ajtai described a construction of one-way functions whose security is equivalent to the difficulty of some
> well known approximation problems in lattices. We show that essentially the same construction can also be used to
> obtain collision-free hashing.

- [FOCS04] Micciancio and Regev. **Worst‐Case to Average‐Case Reductions Based on Gaussian Measures.**
> We show that finding small solutions to random modular linear equations is at least as hard as approximating several
> lattice problems in the worst case within a factor almost linear in the dimension of the lattice. The lattice problems
> we consider are the shortest vector problem, the shortest independent vectors problem, the covering radius problem,
> and the guaranteed distance decoding problem (a variant of the well known closest vector problem). The approximation
> factor we obtain is $n\log^{\O{1}} n$ for all four problems. This greatly improves on all previous work on the subject
> starting from Ajtai’s seminal paper (STOC, 1996), up to the strongest previously known results by Micciancio (SIAM
> J. on Computing, 2004). Our results also bring us closer to the limit where the problems are no longer known to be in
> NP intersect coNP.
>
> Our main tools are Gaussian measures on lattices and the high-dimensional Fourier transform. We start by defining a
> new lattice parameter which determines the amount of Gaussian noise that one has to add to a lattice in order to get
> close to a uniform distribution. In addition to yielding quantitatively much stronger results, the use of this
> parameter allows us to simplify many of the complications in previous work.
>
> Our technical contributions are two-fold. First, we show tight connections between this new parameter and existing
> lattice parameters. One such important connection is between this parameter and the length of the shortest set of
> linearly independent vectors. Second, we prove that the distribution that one obtains after adding Gaussian noise to
> the lattice has the following interesting property: the distribution of the noise vector when conditioning on the
> final value behaves in many respects like the original Gaussian noise vector. In particular, its moments remain
> essentially unchanged.
